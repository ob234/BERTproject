{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "465c7ecdb8134ab4ac838dec390e9462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_495b435fea794ed5a463727562909fa6",
              "IPY_MODEL_8d6c1e9a2d644fc490b5f96d04d51a0d",
              "IPY_MODEL_fcb53d36d3cf4648ab790e2724b586f1"
            ],
            "layout": "IPY_MODEL_bf0df4b229094801bbf1e1a1f58814d1"
          }
        },
        "495b435fea794ed5a463727562909fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b885154990942b3a7878efd9887594b",
            "placeholder": "​",
            "style": "IPY_MODEL_eb4b2836956d4480a4b8c25444c6a363",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "8d6c1e9a2d644fc490b5f96d04d51a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e87865ba346f457a9408945067ad0ad2",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d32365d2ed94b51904e628fc2b2ef10",
            "value": 213450
          }
        },
        "fcb53d36d3cf4648ab790e2724b586f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fabf68ed182428db6f5480adb875541",
            "placeholder": "​",
            "style": "IPY_MODEL_74a032e52313424eaa0fef94c1f8d469",
            "value": " 213k/213k [00:00&lt;00:00, 497kB/s]"
          }
        },
        "bf0df4b229094801bbf1e1a1f58814d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b885154990942b3a7878efd9887594b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb4b2836956d4480a4b8c25444c6a363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e87865ba346f457a9408945067ad0ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d32365d2ed94b51904e628fc2b2ef10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fabf68ed182428db6f5480adb875541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a032e52313424eaa0fef94c1f8d469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "502ac250e5d5493aa3123c8522628c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45c822a680d348748f52895ee3b3d165",
              "IPY_MODEL_b755926544a041419bd3ea5404fd7555",
              "IPY_MODEL_04dda190d02c4a6d9f613c4b48c26e82"
            ],
            "layout": "IPY_MODEL_337eccb1162240ac9f6203d5ce7cb85d"
          }
        },
        "45c822a680d348748f52895ee3b3d165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de99a3a3b73c4ccd8f0d6c405fdf9b59",
            "placeholder": "​",
            "style": "IPY_MODEL_9acff6fc92d94116bd71669b069ef35e",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "b755926544a041419bd3ea5404fd7555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8943403482e4a4f983c1f20e89f2cbb",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd0ce762db3044e08cc69ff292b71357",
            "value": 385
          }
        },
        "04dda190d02c4a6d9f613c4b48c26e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc0ae6d2b61c46c8973676677251939a",
            "placeholder": "​",
            "style": "IPY_MODEL_ff74e180563e48eaa92a64570e772845",
            "value": " 385/385 [00:00&lt;00:00, 33.2kB/s]"
          }
        },
        "337eccb1162240ac9f6203d5ce7cb85d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de99a3a3b73c4ccd8f0d6c405fdf9b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9acff6fc92d94116bd71669b069ef35e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8943403482e4a4f983c1f20e89f2cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd0ce762db3044e08cc69ff292b71357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc0ae6d2b61c46c8973676677251939a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff74e180563e48eaa92a64570e772845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c297ad49995f466b92de6f7e8328d091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_344d1a5caa0846ed9d4bcd6e527d34ad",
              "IPY_MODEL_1d5b5edf8d5c49038866e288547548b5",
              "IPY_MODEL_8b60b13c8eee4e8aae978d4b655ab620"
            ],
            "layout": "IPY_MODEL_9b92670919554321b31c3bf843555cf7"
          }
        },
        "344d1a5caa0846ed9d4bcd6e527d34ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d55019c2fb64b28a5cf5414b69c3cf0",
            "placeholder": "​",
            "style": "IPY_MODEL_b47313939f274e118d0a87582a56bbe1",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "1d5b5edf8d5c49038866e288547548b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3316ac9ea0b34d8abd08d20434407ebb",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e29f53fdd9b249f08aace5768bf66496",
            "value": 435778770
          }
        },
        "8b60b13c8eee4e8aae978d4b655ab620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_326c5080b71544f1a308faadc0600bae",
            "placeholder": "​",
            "style": "IPY_MODEL_bd3e5bfefebb4aa28636373155e1442b",
            "value": " 436M/436M [00:00&lt;00:00, 604MB/s]"
          }
        },
        "9b92670919554321b31c3bf843555cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d55019c2fb64b28a5cf5414b69c3cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b47313939f274e118d0a87582a56bbe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3316ac9ea0b34d8abd08d20434407ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e29f53fdd9b249f08aace5768bf66496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "326c5080b71544f1a308faadc0600bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3e5bfefebb4aa28636373155e1442b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers > /dev/null"
      ],
      "metadata": {
        "id": "_hlhzENkP2lg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "3rW_FPHFCNyh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvm6Wuam8IvO",
        "outputId": "0cbc5a41-4650-4b2e-f774-b57c24b807ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk import word_tokenize\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "class SentDataset(Dataset):\n",
        "    def __init__(self, fname, word2ix=None, df=None):\n",
        "        if df is None:\n",
        "            self.sents = pd.read_csv(fname)\n",
        "        else:\n",
        "            self.sents = df.dropna(subset=['sentence'])\n",
        "        # reset index necessary for getting context sentences when using unlabeled data\n",
        "        #self.sents = self.sents.dropna(subset=['sentence'])\n",
        "        if word2ix is not None:\n",
        "            self.word2ix = word2ix\n",
        "            self.ix2word = {ix:word for word,ix in self.word2ix.items()}\n",
        "        else:\n",
        "            self.word2ix = {'<PAD>': 0}\n",
        "            self.ix2word = {}\n",
        "            self.min_cnt = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sents)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.sents.iloc[idx]\n",
        "        if row.sentence.startswith('[') and row.sentence.endswith(']'):\n",
        "            try:\n",
        "                sentence = eval(row.sentence)\n",
        "            except:\n",
        "                sentence = word_tokenize(row.sentence)\n",
        "        else:\n",
        "            assert isinstance(row.sentence, str)\n",
        "            sentence = word_tokenize(row.sentence)\n",
        "        sent = [x.lower() for x in sentence]\n",
        "        if 'labels' in row:\n",
        "          labels = eval(row.labels)\n",
        "        else:\n",
        "          labels = []\n",
        "        doc_id = row.doc_id\n",
        "        sent_ix = None\n",
        "        if 'sent_index' in row:\n",
        "            sent_ix = row.sent_index\n",
        "        elif 'sent_ix' in row:\n",
        "            sent_ix = row.sent_ix\n",
        "        return sent, labels, doc_id, sent_ix"
      ],
      "metadata": {
        "id": "YOyAoR_01S0b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "import ast\n",
        "def str_to_list(s):\n",
        "    # Use the ast library to safely evaluate the string as a list\n",
        "    return ast.literal_eval(s)\n",
        "\n",
        "sents = pd.read_csv(\"/content/drive/My Drive/Deep Learning Project/Dataset/clip-a-dataset-for-extracting-action-items-for-physicians-from-hospital-discharge-notes-1.0.0/sentence_level.csv\")\n",
        "\n",
        "# Apply the function to the column to convert the strings to lists\n",
        "#sents['sentence'] = sents['sentence'].apply(str_to_list)\n",
        "\n",
        "# Apply the function to the column to convert the strings to lists\n",
        "#sents['labels'] = sents['labels'].apply(str_to_list)\n",
        "train_dataset = pd.read_csv(\"/content/drive/My Drive/Deep Learning Project/Dataset/clip-a-dataset-for-extracting-action-items-for-physicians-from-hospital-discharge-notes-1.0.0/train_ids.csv\", header=None)\n",
        "test_dataset = pd.read_csv(\"/content/drive/My Drive/Deep Learning Project/Dataset/clip-a-dataset-for-extracting-action-items-for-physicians-from-hospital-discharge-notes-1.0.0/test_ids.csv\", header=None)\n",
        "eval_dataset = pd.read_csv(\"/content/drive/My Drive/Deep Learning Project/Dataset/clip-a-dataset-for-extracting-action-items-for-physicians-from-hospital-discharge-notes-1.0.0/val_ids.csv\", header=None)"
      ],
      "metadata": {
        "id": "4svg-BgcjdzE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.columns = ['doc_id']\n",
        "train_dataset = train_dataset.merge(sents, on = \"doc_id\")\n",
        "test_dataset.columns = ['doc_id']\n",
        "test_dataset = test_dataset.merge(sents, on = \"doc_id\")\n",
        "eval_dataset.columns = ['doc_id']\n",
        "eval_dataset = eval_dataset.merge(sents, on = \"doc_id\")"
      ],
      "metadata": {
        "id": "upiBkT1P1T6u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SentDataset('contet',df =train_dataset)\n",
        "eval_dataset = SentDataset('content',df=eval_dataset)\n",
        "test_dataset = SentDataset('content',df=test_dataset)"
      ],
      "metadata": {
        "id": "MJnrJn5-_u4_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer1 = BertTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')"
      ],
      "metadata": {
        "id": "Z06uyBeyLQ7D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "465c7ecdb8134ab4ac838dec390e9462",
            "495b435fea794ed5a463727562909fa6",
            "8d6c1e9a2d644fc490b5f96d04d51a0d",
            "fcb53d36d3cf4648ab790e2724b586f1",
            "bf0df4b229094801bbf1e1a1f58814d1",
            "1b885154990942b3a7878efd9887594b",
            "eb4b2836956d4480a4b8c25444c6a363",
            "e87865ba346f457a9408945067ad0ad2",
            "9d32365d2ed94b51904e628fc2b2ef10",
            "3fabf68ed182428db6f5480adb875541",
            "74a032e52313424eaa0fef94c1f8d469",
            "502ac250e5d5493aa3123c8522628c28",
            "45c822a680d348748f52895ee3b3d165",
            "b755926544a041419bd3ea5404fd7555",
            "04dda190d02c4a6d9f613c4b48c26e82",
            "337eccb1162240ac9f6203d5ce7cb85d",
            "de99a3a3b73c4ccd8f0d6c405fdf9b59",
            "9acff6fc92d94116bd71669b069ef35e",
            "f8943403482e4a4f983c1f20e89f2cbb",
            "dd0ce762db3044e08cc69ff292b71357",
            "cc0ae6d2b61c46c8973676677251939a",
            "ff74e180563e48eaa92a64570e772845"
          ]
        },
        "outputId": "e2a4face-d3e8-4f0c-8ccb-74afa8d43bbf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "465c7ecdb8134ab4ac838dec390e9462"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "502ac250e5d5493aa3123c8522628c28"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets & Dataloaders\n"
      ],
      "metadata": {
        "id": "CgQdrl2pQkno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "metadata": {
        "id": "KU-tl0cIRFY-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collator(batch, tokenizer, eval=False, doc_position=False):\n",
        "    # standard bert collator that applies the right label for the training task\n",
        "    sents = []\n",
        "    labels = []\n",
        "    doc_poses = []\n",
        "    doc_ids = []\n",
        "    sent_ixs = []\n",
        "    for sent, label, doc_id, sent_ix in batch:\n",
        "        sents.append(' '.join(sent))\n",
        "        label = multilabel_labeler(label)\n",
        "        labels.append(label)\n",
        "        doc_ids.append(doc_id)\n",
        "        sent_ixs.append(sent_ix)\n",
        "    tokd = tokenizer(sents, padding=True, max_length = 512, truncation=True)\n",
        "    input_ids, token_type_ids, attention_mask = tokd['input_ids'], tokd['token_type_ids'], tokd['attention_mask']\n",
        "    toks = torch.LongTensor(input_ids)\n",
        "    mask = torch.LongTensor(attention_mask)\n",
        "    labels = torch.Tensor(labels)\n",
        "    # for whatever reason, pytorch's cross entropy requires long labels but BCE doesn't\n",
        "    if not eval:\n",
        "        return {'input_ids': toks, 'attention_mask': mask, 'labels': labels, 'doc_ids': doc_ids, 'sent_ixs': sent_ixs}\n",
        "    else:\n",
        "        return {'input_ids': toks, 'attention_mask': mask, 'labels': labels, 'sentences': sents, 'doc_ids': doc_ids, 'sent_ixs': sent_ixs}\n",
        "\n",
        "data_collator = lambda x: collator(x, tokenizer = tokenizer1)\n",
        "eval_collate_fn = lambda x: collator(x, tokenizer =tokenizer1, eval=True)"
      ],
      "metadata": {
        "id": "Tcr3dZOuwJCG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import tqdm\n",
        "\n",
        "# class BertDataset(torch.utils.data.Dataset):\n",
        "#   def __init__(self, txt_list, tokenizer, max_length=512):\n",
        "#     self.tokenizer = tokenizer\n",
        "#     self.sents = []\n",
        "#     self.labels = []\n",
        "#     self.doc_poses = []\n",
        "#     self.doc_ids = []\n",
        "#     self.sent_ixs = []\n",
        "#     self.input_ids = []\n",
        "#     self.token_type_ids = []\n",
        "#     self.attention_maks = []\n",
        "\n",
        "\n",
        "#     for doc_id, sent_ix, sent, label in tqdm.tqdm(txt_list.values, desc=\"Tokenizing data\"):\n",
        "#         #sents.append(' '.join(sent))\n",
        "#         tokd = tokenizer(sent, padding=True, max_length = 512)\n",
        "#         self.input_ids.append(torch.Tensor(tokd['input_ids']))\n",
        "#         self.token_type_ids.append(tokd['token_type_ids'])\n",
        "#         self.attention_maks.append(torch.Tensor(tokd['attention_mask']))\n",
        "#         label = multilabel_labeler(label)\n",
        "#         self.labels.append(label)\n",
        "#         self.doc_ids.append(doc_id)\n",
        "#         self.sent_ixs.append(sent_ix)\n",
        "#     self.labels = torch.Tensor(self.labels)\n",
        "    \n",
        "#   def __len__(self):\n",
        "#     return len(self.sent_ixs)\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#     return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_maks[idx], 'labels': self.labels[idx], 'doc_ids': self.doc_ids[idx], 'sent_ixs': self.sent_ixs[idx]} "
      ],
      "metadata": {
        "id": "PF8HQ_vbSHm5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_TYPES = ['I-Imaging-related followup',\n",
        " 'I-Appointment-related followup',\n",
        " 'I-Medication-related followups',\n",
        " 'I-Procedure-related followup',\n",
        " 'I-Lab-related followup',\n",
        " 'I-Case-specific instructions for patient',\n",
        " 'I-Other helpful contextual information',\n",
        " ]\n",
        "\n",
        "label2abbrev = {'I-Imaging-related followup': 'Imaging',\n",
        "        'I-Appointment-related followup': 'Appointment',\n",
        "        'I-Medication-related followups': 'Medication',\n",
        "        'I-Procedure-related followup': 'Procedure',\n",
        "        'I-Lab-related followup': 'Lab',\n",
        "        'I-Case-specific instructions for patient': 'Patient instructions',\n",
        "        'I-Other helpful contextual information': 'Other',\n",
        " }\n",
        "\n",
        "def multilabel_labeler(label):\n",
        "    # convert list of label names to a multi-hot array\n",
        "    if isinstance(label, str):\n",
        "        label = eval(label)\n",
        "    label_ixs = [LABEL_TYPES.index(l) for l in label]\n",
        "    label = np.zeros(len(LABEL_TYPES))\n",
        "    label[label_ixs] = 1\n",
        "    return label"
      ],
      "metadata": {
        "id": "lKjcgW8Ryz8N"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train_dataset = BertDataset(train_dataset, tokenizer, max_length=512, collate_fn=data_collator)\n",
        "# eval_dataset = BertDataset(eval_dataset, tokenizer, max_length=512, collate_fn=eval_collate_fn)\n",
        "\n",
        "# print()\n",
        "# print('{:>5,} training samples'.format(len(train_dataset)))\n",
        "# print('{:>5,} validation samples'.format(len(eval_dataset)))"
      ],
      "metadata": {
        "id": "f21UWyng9-Al"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "  train_dataset,\n",
        "  batch_size=batch_size,\n",
        "  collate_fn=data_collator\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "  eval_dataset,\n",
        "  shuffle=False,\n",
        "  batch_size=1,\n",
        "  collate_fn=eval_collate_fn\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=1, shuffle=False, collate_fn=eval_collate_fn\n",
        "    )"
      ],
      "metadata": {
        "id": "A4BrtN3cXp_y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune BERT Model"
      ],
      "metadata": {
        "id": "h2OVhp8rFGA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertPreTrainedModel, BertModel, BertForMaskedLM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss, KLDivLoss\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BioClinicalBertForSequenceMultilabelClassification(BertPreTrainedModel):\n",
        "    \"\"\"\n",
        "        simple mod of MiniBERT to accept multilabel or binary task\n",
        "        there may or may not be a class in huggingface that does this but this is here for historical reasons\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.biobert = BertModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def add_doc_position_feature(self, config):\n",
        "        self.classifier = nn.Linear(config.hidden_size+1, config.num_labels)\n",
        "\n",
        "    def set_task(self, task):\n",
        "        self.task = task\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        doc_positions=None,\n",
        "    ):\n",
        "        outputs = self.biobert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        if doc_positions is not None and len(doc_positions) > 0:\n",
        "            pooled_output = torch.cat((pooled_output, doc_positions.unsqueeze(1)), dim=1)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        if labels is not None:\n",
        "            loss = F.binary_cross_entropy_with_logits(outputs[0], labels)\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lv38x2zLTmJo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_set = LABEL_TYPES\n",
        "num_labels = len(label_set)\n",
        "\n",
        "label2id = {label:ix for ix,label in enumerate(label_set)}\n",
        "id2label = {ix:label for label,ix in label2id.items()}\n",
        "config = BertConfig.from_pretrained(\n",
        "        'emilyalsentzer/Bio_ClinicalBERT',\n",
        "        num_labels=num_labels,\n",
        "        finetuning_task=\"text_classification\",\n",
        "        label2id=label2id,\n",
        "        id2label=id2label,\n",
        "    )"
      ],
      "metadata": {
        "id": "bs7AN7UKHy5A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "model = BioClinicalBertForSequenceMultilabelClassification.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', config=config)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "c297ad49995f466b92de6f7e8328d091",
            "344d1a5caa0846ed9d4bcd6e527d34ad",
            "1d5b5edf8d5c49038866e288547548b5",
            "8b60b13c8eee4e8aae978d4b655ab620",
            "9b92670919554321b31c3bf843555cf7",
            "4d55019c2fb64b28a5cf5414b69c3cf0",
            "b47313939f274e118d0a87582a56bbe1",
            "3316ac9ea0b34d8abd08d20434407ebb",
            "e29f53fdd9b249f08aace5768bf66496",
            "326c5080b71544f1a308faadc0600bae",
            "bd3e5bfefebb4aa28636373155e1442b"
          ]
        },
        "id": "2B-HztvrJs7Q",
        "outputId": "ff8cc61d-407c-426e-8716-f4d66e66f901"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c297ad49995f466b92de6f7e8328d091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BioClinicalBertForSequenceMultilabelClassification: ['bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.2.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'cls.predictions.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.dense.bias', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'cls.predictions.decoder.weight', 'bert.pooler.dense.bias', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias']\n",
            "- This IS expected if you are initializing BioClinicalBertForSequenceMultilabelClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BioClinicalBertForSequenceMultilabelClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BioClinicalBertForSequenceMultilabelClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['bert.biobert.encoder.layer.9.attention.self.value.weight', 'bert.biobert.encoder.layer.3.intermediate.dense.bias', 'bert.biobert.encoder.layer.6.output.LayerNorm.weight', 'bert.biobert.encoder.layer.4.attention.self.value.bias', 'bert.biobert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.2.attention.self.key.bias', 'bert.biobert.encoder.layer.3.attention.output.dense.weight', 'bert.biobert.encoder.layer.3.intermediate.dense.weight', 'bert.biobert.encoder.layer.6.attention.output.dense.bias', 'bert.biobert.encoder.layer.10.attention.self.query.weight', 'bert.biobert.encoder.layer.3.attention.self.query.bias', 'bert.biobert.encoder.layer.11.attention.self.key.weight', 'bert.biobert.encoder.layer.3.attention.self.query.weight', 'bert.biobert.encoder.layer.1.output.dense.weight', 'bert.biobert.encoder.layer.5.intermediate.dense.bias', 'bert.biobert.encoder.layer.7.output.dense.bias', 'bert.biobert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.10.intermediate.dense.weight', 'bert.biobert.encoder.layer.2.output.dense.weight', 'bert.biobert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.8.attention.output.dense.bias', 'bert.biobert.encoder.layer.5.intermediate.dense.weight', 'bert.biobert.encoder.layer.10.intermediate.dense.bias', 'bert.biobert.encoder.layer.8.attention.self.value.bias', 'bert.biobert.encoder.layer.6.intermediate.dense.bias', 'bert.biobert.encoder.layer.11.output.LayerNorm.bias', 'bert.biobert.encoder.layer.6.intermediate.dense.weight', 'bert.biobert.encoder.layer.0.intermediate.dense.bias', 'bert.biobert.encoder.layer.9.attention.output.dense.weight', 'bert.biobert.encoder.layer.3.attention.self.value.weight', 'bert.biobert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.5.output.LayerNorm.weight', 'bert.biobert.encoder.layer.1.output.LayerNorm.weight', 'bert.biobert.encoder.layer.0.attention.output.dense.bias', 'bert.biobert.encoder.layer.0.attention.self.value.weight', 'bert.biobert.encoder.layer.6.output.dense.bias', 'bert.biobert.encoder.layer.8.output.LayerNorm.bias', 'bert.biobert.encoder.layer.6.attention.self.key.weight', 'bert.biobert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.0.attention.output.dense.weight', 'bert.biobert.encoder.layer.9.intermediate.dense.bias', 'bert.biobert.encoder.layer.10.attention.self.key.bias', 'bert.biobert.encoder.layer.6.output.LayerNorm.bias', 'bert.biobert.encoder.layer.10.attention.self.value.bias', 'bert.biobert.encoder.layer.11.attention.self.value.weight', 'bert.biobert.encoder.layer.9.attention.output.dense.bias', 'bert.biobert.encoder.layer.11.attention.self.query.bias', 'bert.biobert.encoder.layer.2.attention.self.value.bias', 'bert.biobert.encoder.layer.7.intermediate.dense.bias', 'bert.biobert.encoder.layer.11.intermediate.dense.weight', 'bert.biobert.encoder.layer.9.attention.self.value.bias', 'bert.biobert.encoder.layer.6.attention.self.query.bias', 'bert.biobert.encoder.layer.1.attention.self.query.weight', 'bert.biobert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.1.intermediate.dense.weight', 'bert.biobert.encoder.layer.4.attention.output.dense.bias', 'bert.biobert.encoder.layer.7.attention.self.key.bias', 'bert.biobert.encoder.layer.2.output.dense.bias', 'bert.biobert.encoder.layer.6.attention.self.query.weight', 'bert.biobert.encoder.layer.8.attention.self.query.weight', 'bert.biobert.encoder.layer.10.output.dense.weight', 'bert.biobert.encoder.layer.10.attention.output.dense.weight', 'bert.biobert.encoder.layer.9.attention.self.query.bias', 'bert.biobert.encoder.layer.0.output.LayerNorm.bias', 'bert.biobert.encoder.layer.7.attention.self.query.weight', 'bert.biobert.encoder.layer.3.attention.output.dense.bias', 'bert.biobert.encoder.layer.2.attention.self.value.weight', 'bert.biobert.encoder.layer.2.output.LayerNorm.bias', 'bert.biobert.encoder.layer.3.attention.self.key.bias', 'bert.biobert.pooler.dense.bias', 'bert.biobert.encoder.layer.0.output.dense.bias', 'bert.biobert.embeddings.word_embeddings.weight', 'bert.biobert.encoder.layer.11.attention.self.query.weight', 'bert.biobert.encoder.layer.3.output.dense.bias', 'bert.biobert.encoder.layer.7.intermediate.dense.weight', 'bert.biobert.encoder.layer.1.output.dense.bias', 'bert.biobert.encoder.layer.6.attention.output.dense.weight', 'bert.biobert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.5.output.LayerNorm.bias', 'bert.biobert.encoder.layer.9.output.LayerNorm.weight', 'bert.biobert.encoder.layer.8.attention.self.key.weight', 'bert.biobert.encoder.layer.3.attention.self.value.bias', 'bert.biobert.encoder.layer.1.attention.self.query.bias', 'bert.biobert.encoder.layer.0.attention.self.value.bias', 'bert.biobert.encoder.layer.9.attention.self.key.bias', 'bert.biobert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.9.output.dense.bias', 'bert.biobert.encoder.layer.5.attention.output.dense.bias', 'bert.biobert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.7.output.dense.weight', 'bert.biobert.encoder.layer.8.output.LayerNorm.weight', 'bert.biobert.encoder.layer.7.attention.self.value.weight', 'bert.biobert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.biobert.pooler.dense.weight', 'bert.biobert.encoder.layer.4.attention.self.query.weight', 'bert.biobert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.10.attention.self.value.weight', 'bert.biobert.encoder.layer.5.output.dense.weight', 'bert.biobert.encoder.layer.0.attention.self.key.weight', 'bert.biobert.encoder.layer.2.output.LayerNorm.weight', 'bert.biobert.encoder.layer.0.output.LayerNorm.weight', 'bert.biobert.encoder.layer.1.intermediate.dense.bias', 'bert.biobert.encoder.layer.1.output.LayerNorm.bias', 'bert.biobert.encoder.layer.0.attention.self.query.bias', 'bert.biobert.encoder.layer.4.attention.self.key.bias', 'bert.biobert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.11.output.dense.bias', 'bert.biobert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.4.output.dense.bias', 'bert.biobert.encoder.layer.1.attention.self.key.bias', 'bert.biobert.encoder.layer.4.intermediate.dense.bias', 'bert.biobert.encoder.layer.5.attention.self.query.weight', 'bert.biobert.encoder.layer.7.output.LayerNorm.weight', 'bert.biobert.encoder.layer.8.attention.self.value.weight', 'bert.biobert.encoder.layer.5.attention.output.dense.weight', 'bert.biobert.encoder.layer.4.attention.output.dense.weight', 'bert.biobert.encoder.layer.7.attention.self.value.bias', 'bert.biobert.encoder.layer.1.attention.self.key.weight', 'bert.biobert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.8.attention.self.key.bias', 'bert.biobert.encoder.layer.8.attention.output.dense.weight', 'bert.biobert.encoder.layer.11.attention.self.key.bias', 'bert.biobert.encoder.layer.4.output.LayerNorm.weight', 'bert.biobert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.3.output.LayerNorm.bias', 'bert.biobert.encoder.layer.6.attention.self.value.weight', 'bert.biobert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.biobert.embeddings.LayerNorm.weight', 'bert.biobert.encoder.layer.6.attention.self.key.bias', 'bert.biobert.encoder.layer.10.output.LayerNorm.bias', 'bert.biobert.encoder.layer.5.output.dense.bias', 'bert.biobert.embeddings.token_type_embeddings.weight', 'bert.biobert.encoder.layer.1.attention.self.value.weight', 'bert.biobert.encoder.layer.3.output.LayerNorm.weight', 'bert.biobert.encoder.layer.8.output.dense.weight', 'bert.biobert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.0.output.dense.weight', 'bert.biobert.encoder.layer.5.attention.self.value.weight', 'bert.biobert.encoder.layer.11.output.LayerNorm.weight', 'bert.biobert.encoder.layer.9.attention.self.key.weight', 'bert.biobert.encoder.layer.9.intermediate.dense.weight', 'bert.biobert.encoder.layer.3.output.dense.weight', 'bert.biobert.encoder.layer.4.intermediate.dense.weight', 'bert.biobert.encoder.layer.5.attention.self.key.weight', 'bert.biobert.encoder.layer.7.attention.self.query.bias', 'bert.biobert.encoder.layer.10.attention.self.key.weight', 'bert.biobert.encoder.layer.11.attention.output.dense.weight', 'bert.biobert.encoder.layer.10.attention.output.dense.bias', 'bert.biobert.encoder.layer.7.attention.self.key.weight', 'bert.biobert.encoder.layer.2.intermediate.dense.weight', 'bert.biobert.encoder.layer.0.intermediate.dense.weight', 'bert.biobert.encoder.layer.7.output.LayerNorm.bias', 'bert.biobert.encoder.layer.7.attention.output.dense.bias', 'bert.biobert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.1.attention.self.value.bias', 'bert.biobert.encoder.layer.11.intermediate.dense.bias', 'bert.biobert.encoder.layer.2.attention.output.dense.weight', 'bert.biobert.encoder.layer.3.attention.self.key.weight', 'bert.biobert.encoder.layer.8.intermediate.dense.bias', 'bert.biobert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.10.attention.self.query.bias', 'bert.biobert.encoder.layer.11.attention.self.value.bias', 'bert.biobert.encoder.layer.10.output.LayerNorm.weight', 'bert.biobert.encoder.layer.1.attention.output.dense.weight', 'bert.biobert.encoder.layer.8.output.dense.bias', 'bert.biobert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.9.output.LayerNorm.bias', 'bert.biobert.encoder.layer.10.output.dense.bias', 'bert.biobert.encoder.layer.4.attention.self.key.weight', 'bert.biobert.encoder.layer.2.intermediate.dense.bias', 'bert.biobert.encoder.layer.0.attention.self.key.bias', 'bert.biobert.encoder.layer.2.attention.self.key.weight', 'bert.biobert.encoder.layer.5.attention.self.key.bias', 'bert.biobert.encoder.layer.5.attention.self.value.bias', 'bert.biobert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.2.attention.self.query.weight', 'bert.biobert.encoder.layer.9.output.dense.weight', 'bert.biobert.encoder.layer.11.output.dense.weight', 'bert.biobert.encoder.layer.2.attention.output.dense.bias', 'bert.biobert.encoder.layer.4.attention.self.query.bias', 'bert.biobert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.biobert.encoder.layer.4.output.dense.weight', 'bert.biobert.encoder.layer.4.attention.self.value.weight', 'bert.classifier.weight', 'bert.biobert.encoder.layer.11.attention.output.dense.bias', 'bert.biobert.encoder.layer.1.attention.output.dense.bias', 'bert.biobert.encoder.layer.5.attention.self.query.bias', 'bert.biobert.encoder.layer.8.intermediate.dense.weight', 'bert.biobert.embeddings.LayerNorm.bias', 'bert.biobert.encoder.layer.2.attention.self.query.bias', 'bert.biobert.embeddings.position_embeddings.weight', 'bert.biobert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.biobert.encoder.layer.8.attention.self.query.bias', 'bert.biobert.encoder.layer.0.attention.self.query.weight', 'bert.biobert.encoder.layer.6.output.dense.weight', 'bert.biobert.encoder.layer.7.attention.output.dense.weight', 'bert.biobert.encoder.layer.4.output.LayerNorm.bias', 'bert.biobert.encoder.layer.9.attention.self.query.weight', 'bert.biobert.encoder.layer.6.attention.self.value.bias', 'bert.classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "freeze weights if needed"
      ],
      "metadata": {
        "id": "lfF5PFP4XkPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, params in model.named_parameters():\n",
        "  if name.startswith('biobert.embeddings.'):\n",
        "    params.requires_grad = False\n",
        "  if name.startswith('biobert.encoder.layer.0'):\n",
        "    params.requires_grad = False\n",
        "  if name.startswith('biobert.encoder.layer.1'):\n",
        "    params.requires_grad = False\n",
        "  if name.startswith('biobert.encoder.layer.2'):\n",
        "    params.requires_grad = False\n",
        "  if name.startswith('biobert.encoder.layer.3'):\n",
        "    params.requires_grad = False\n",
        "  if name.startswith('biobert.encoder.layer.4'):\n",
        "    params.requires_grad = True\n",
        "  if name.startswith('biobert.encoder.layer.5'):\n",
        "    params.requires_grad = True\n",
        "  if name.startswith('biobert.encoder.layer.6'):\n",
        "    params.requires_grad = True\n",
        "  if name.startswith('biobert.encoder.layer.7'):\n",
        "    params.requires_grad = True\n",
        "  if name.startswith('biobert.encoder.layer.8'):\n",
        "    params.requires_grad = True\n",
        "  if name.startswith('biobert.encoder.layer.9'):\n",
        "    params.requires_grad = True\n",
        "  if name.startswith('biobert.encoder.layer.10'):\n",
        "    params.requires_grad = True\n",
        "  if name.startswith('biobert.encoder.layer.11'):\n",
        "    params.requires_grad = True"
      ],
      "metadata": {
        "id": "epNJ1zr8_-EF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, params in model.named_parameters():\n",
        "  print(name)\n",
        "  print(params.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5LLolR8LwTX",
        "outputId": "bd02ef99-3c91-4d4c-b5a4-ccf8aee06888"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "biobert.embeddings.word_embeddings.weight\n",
            "False\n",
            "biobert.embeddings.position_embeddings.weight\n",
            "False\n",
            "biobert.embeddings.token_type_embeddings.weight\n",
            "False\n",
            "biobert.embeddings.LayerNorm.weight\n",
            "False\n",
            "biobert.embeddings.LayerNorm.bias\n",
            "False\n",
            "biobert.encoder.layer.0.attention.self.query.weight\n",
            "False\n",
            "biobert.encoder.layer.0.attention.self.query.bias\n",
            "False\n",
            "biobert.encoder.layer.0.attention.self.key.weight\n",
            "False\n",
            "biobert.encoder.layer.0.attention.self.key.bias\n",
            "False\n",
            "biobert.encoder.layer.0.attention.self.value.weight\n",
            "False\n",
            "biobert.encoder.layer.0.attention.self.value.bias\n",
            "False\n",
            "biobert.encoder.layer.0.attention.output.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.0.attention.output.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "False\n",
            "biobert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "False\n",
            "biobert.encoder.layer.0.intermediate.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.0.intermediate.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.0.output.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.0.output.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.0.output.LayerNorm.weight\n",
            "False\n",
            "biobert.encoder.layer.0.output.LayerNorm.bias\n",
            "False\n",
            "biobert.encoder.layer.1.attention.self.query.weight\n",
            "False\n",
            "biobert.encoder.layer.1.attention.self.query.bias\n",
            "False\n",
            "biobert.encoder.layer.1.attention.self.key.weight\n",
            "False\n",
            "biobert.encoder.layer.1.attention.self.key.bias\n",
            "False\n",
            "biobert.encoder.layer.1.attention.self.value.weight\n",
            "False\n",
            "biobert.encoder.layer.1.attention.self.value.bias\n",
            "False\n",
            "biobert.encoder.layer.1.attention.output.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.1.attention.output.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "False\n",
            "biobert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "False\n",
            "biobert.encoder.layer.1.intermediate.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.1.intermediate.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.1.output.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.1.output.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.1.output.LayerNorm.weight\n",
            "False\n",
            "biobert.encoder.layer.1.output.LayerNorm.bias\n",
            "False\n",
            "biobert.encoder.layer.2.attention.self.query.weight\n",
            "False\n",
            "biobert.encoder.layer.2.attention.self.query.bias\n",
            "False\n",
            "biobert.encoder.layer.2.attention.self.key.weight\n",
            "False\n",
            "biobert.encoder.layer.2.attention.self.key.bias\n",
            "False\n",
            "biobert.encoder.layer.2.attention.self.value.weight\n",
            "False\n",
            "biobert.encoder.layer.2.attention.self.value.bias\n",
            "False\n",
            "biobert.encoder.layer.2.attention.output.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.2.attention.output.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "False\n",
            "biobert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "False\n",
            "biobert.encoder.layer.2.intermediate.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.2.intermediate.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.2.output.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.2.output.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.2.output.LayerNorm.weight\n",
            "False\n",
            "biobert.encoder.layer.2.output.LayerNorm.bias\n",
            "False\n",
            "biobert.encoder.layer.3.attention.self.query.weight\n",
            "False\n",
            "biobert.encoder.layer.3.attention.self.query.bias\n",
            "False\n",
            "biobert.encoder.layer.3.attention.self.key.weight\n",
            "False\n",
            "biobert.encoder.layer.3.attention.self.key.bias\n",
            "False\n",
            "biobert.encoder.layer.3.attention.self.value.weight\n",
            "False\n",
            "biobert.encoder.layer.3.attention.self.value.bias\n",
            "False\n",
            "biobert.encoder.layer.3.attention.output.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.3.attention.output.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "False\n",
            "biobert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "False\n",
            "biobert.encoder.layer.3.intermediate.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.3.intermediate.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.3.output.dense.weight\n",
            "False\n",
            "biobert.encoder.layer.3.output.dense.bias\n",
            "False\n",
            "biobert.encoder.layer.3.output.LayerNorm.weight\n",
            "False\n",
            "biobert.encoder.layer.3.output.LayerNorm.bias\n",
            "False\n",
            "biobert.encoder.layer.4.attention.self.query.weight\n",
            "True\n",
            "biobert.encoder.layer.4.attention.self.query.bias\n",
            "True\n",
            "biobert.encoder.layer.4.attention.self.key.weight\n",
            "True\n",
            "biobert.encoder.layer.4.attention.self.key.bias\n",
            "True\n",
            "biobert.encoder.layer.4.attention.self.value.weight\n",
            "True\n",
            "biobert.encoder.layer.4.attention.self.value.bias\n",
            "True\n",
            "biobert.encoder.layer.4.attention.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.4.attention.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.4.intermediate.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.4.intermediate.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.4.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.4.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.4.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.4.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.5.attention.self.query.weight\n",
            "True\n",
            "biobert.encoder.layer.5.attention.self.query.bias\n",
            "True\n",
            "biobert.encoder.layer.5.attention.self.key.weight\n",
            "True\n",
            "biobert.encoder.layer.5.attention.self.key.bias\n",
            "True\n",
            "biobert.encoder.layer.5.attention.self.value.weight\n",
            "True\n",
            "biobert.encoder.layer.5.attention.self.value.bias\n",
            "True\n",
            "biobert.encoder.layer.5.attention.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.5.attention.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.5.intermediate.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.5.intermediate.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.5.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.5.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.5.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.5.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.6.attention.self.query.weight\n",
            "True\n",
            "biobert.encoder.layer.6.attention.self.query.bias\n",
            "True\n",
            "biobert.encoder.layer.6.attention.self.key.weight\n",
            "True\n",
            "biobert.encoder.layer.6.attention.self.key.bias\n",
            "True\n",
            "biobert.encoder.layer.6.attention.self.value.weight\n",
            "True\n",
            "biobert.encoder.layer.6.attention.self.value.bias\n",
            "True\n",
            "biobert.encoder.layer.6.attention.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.6.attention.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.6.intermediate.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.6.intermediate.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.6.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.6.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.6.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.6.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.7.attention.self.query.weight\n",
            "True\n",
            "biobert.encoder.layer.7.attention.self.query.bias\n",
            "True\n",
            "biobert.encoder.layer.7.attention.self.key.weight\n",
            "True\n",
            "biobert.encoder.layer.7.attention.self.key.bias\n",
            "True\n",
            "biobert.encoder.layer.7.attention.self.value.weight\n",
            "True\n",
            "biobert.encoder.layer.7.attention.self.value.bias\n",
            "True\n",
            "biobert.encoder.layer.7.attention.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.7.attention.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.7.intermediate.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.7.intermediate.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.7.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.7.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.7.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.7.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.8.attention.self.query.weight\n",
            "True\n",
            "biobert.encoder.layer.8.attention.self.query.bias\n",
            "True\n",
            "biobert.encoder.layer.8.attention.self.key.weight\n",
            "True\n",
            "biobert.encoder.layer.8.attention.self.key.bias\n",
            "True\n",
            "biobert.encoder.layer.8.attention.self.value.weight\n",
            "True\n",
            "biobert.encoder.layer.8.attention.self.value.bias\n",
            "True\n",
            "biobert.encoder.layer.8.attention.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.8.attention.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.8.intermediate.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.8.intermediate.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.8.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.8.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.8.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.8.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.9.attention.self.query.weight\n",
            "True\n",
            "biobert.encoder.layer.9.attention.self.query.bias\n",
            "True\n",
            "biobert.encoder.layer.9.attention.self.key.weight\n",
            "True\n",
            "biobert.encoder.layer.9.attention.self.key.bias\n",
            "True\n",
            "biobert.encoder.layer.9.attention.self.value.weight\n",
            "True\n",
            "biobert.encoder.layer.9.attention.self.value.bias\n",
            "True\n",
            "biobert.encoder.layer.9.attention.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.9.attention.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.9.intermediate.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.9.intermediate.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.9.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.9.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.9.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.9.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.10.attention.self.query.weight\n",
            "True\n",
            "biobert.encoder.layer.10.attention.self.query.bias\n",
            "True\n",
            "biobert.encoder.layer.10.attention.self.key.weight\n",
            "True\n",
            "biobert.encoder.layer.10.attention.self.key.bias\n",
            "True\n",
            "biobert.encoder.layer.10.attention.self.value.weight\n",
            "True\n",
            "biobert.encoder.layer.10.attention.self.value.bias\n",
            "True\n",
            "biobert.encoder.layer.10.attention.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.10.attention.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.10.intermediate.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.10.intermediate.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.10.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.10.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.10.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.10.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.11.attention.self.query.weight\n",
            "True\n",
            "biobert.encoder.layer.11.attention.self.query.bias\n",
            "True\n",
            "biobert.encoder.layer.11.attention.self.key.weight\n",
            "True\n",
            "biobert.encoder.layer.11.attention.self.key.bias\n",
            "True\n",
            "biobert.encoder.layer.11.attention.self.value.weight\n",
            "True\n",
            "biobert.encoder.layer.11.attention.self.value.bias\n",
            "True\n",
            "biobert.encoder.layer.11.attention.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.11.attention.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "True\n",
            "biobert.encoder.layer.11.intermediate.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.11.intermediate.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.11.output.dense.weight\n",
            "True\n",
            "biobert.encoder.layer.11.output.dense.bias\n",
            "True\n",
            "biobert.encoder.layer.11.output.LayerNorm.weight\n",
            "True\n",
            "biobert.encoder.layer.11.output.LayerNorm.bias\n",
            "True\n",
            "biobert.pooler.dense.weight\n",
            "True\n",
            "biobert.pooler.dense.bias\n",
            "True\n",
            "classifier.weight\n",
            "True\n",
            "classifier.bias\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "timestamp = time.strftime('%b_%d_%H:%M:%S', time.localtime())\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YZDa2pVUipQ",
        "outputId": "66eb19c2-0e9d-4c1b-bf60-42cf6f85720f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute Predictions"
      ],
      "metadata": {
        "id": "qleopQt9fc4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gather_predictions(model, loader, device, doc_position=False, save_preds=False, max_preds=1e9):\n",
        "    # run through data loader and get model predictions\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        yhat_raw = np.zeros((len(loader), 7))\n",
        "        yhat = np.zeros((len(loader), 7))\n",
        "        y = np.zeros((len(loader), 7))\n",
        "        sentences = []\n",
        "        doc_ids = []\n",
        "        sent_ixs = []\n",
        "        for ix, x in enumerate(loader):\n",
        "            if ix >= max_preds:\n",
        "                break\n",
        "            for k, v in x.items():\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    x[k] = v.to(device)\n",
        "            sentences.extend(x['sentences'])\n",
        "            doc_ids.extend(x['doc_ids'])\n",
        "            sent_ixs.extend(x['sent_ixs'])\n",
        "            inputs = {'input_ids': x['input_ids'], 'attention_mask': x['attention_mask'], 'labels': x['labels']}\n",
        "            if 'token_type_ids' in x:\n",
        "              inputs['token_type_ids'] = x['token_type_ids']\n",
        "            loss, pred = model(**inputs)\n",
        "            pred = torch.sigmoid(pred)\n",
        "            pred = pred.cpu().numpy()\n",
        "            yhat_raw[ix] = pred\n",
        "            yhat[ix] = np.round(pred)\n",
        "            y[ix] = x['labels'].cpu().numpy()[0]\n",
        "    return yhat_raw, yhat, y, sentences, doc_ids, sent_ixs"
      ],
      "metadata": {
        "id": "4Sg_mFp-VIXq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics"
      ],
      "metadata": {
        "id": "m5vysVhefOOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import time\n",
        "\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "metadata": {
        "id": "uuZdTrAJlg5p"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import csv\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def auc_metrics(yhat_raw, y, ymic):\n",
        "    if yhat_raw.shape[0] <= 1:\n",
        "        return\n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    roc_auc = {}\n",
        "    #get AUC for each label individually\n",
        "    relevant_labels = []\n",
        "    auc_labels = {}\n",
        "    for i in range(y.shape[1]):\n",
        "        #only if there are true positives for this label\n",
        "        if y[:,i].sum() > 0:\n",
        "            fpr[i], tpr[i], _ = roc_curve(y[:,i], yhat_raw[:,i])\n",
        "            if len(fpr[i]) > 1 and len(tpr[i]) > 1:\n",
        "                auc_score = auc(fpr[i], tpr[i])\n",
        "                if not np.isnan(auc_score): \n",
        "                    auc_labels[\"auc_%d\" % i] = auc_score\n",
        "                    relevant_labels.append(i)\n",
        "\n",
        "    #macro-AUC: just average the auc scores\n",
        "    aucs = []\n",
        "    for i in relevant_labels:\n",
        "        aucs.append(auc_labels['auc_%d' % i])\n",
        "    roc_auc['auc_macro'] = np.mean(aucs)\n",
        "\n",
        "    #micro-AUC: just look at each individual prediction\n",
        "    yhatmic = yhat_raw.ravel()\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ymic, yhatmic) \n",
        "    roc_auc[\"auc_micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "def union_size(yhat, y, axis):\n",
        "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
        "    return np.logical_or(yhat, y).sum(axis=axis).astype(float)\n",
        "\n",
        "def intersect_size(yhat, y, axis):\n",
        "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
        "    return np.logical_and(yhat, y).sum(axis=axis).astype(float)\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "#MACRO METRICS: calculate metric for each label and average across labels\n",
        "#########################################################################\n",
        "\n",
        "def macro_accuracy(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (union_size(yhat, y, 0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_precision(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (yhat.sum(axis=0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_recall(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (y.sum(axis=0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_f1(yhat, y):\n",
        "    prec = macro_precision(yhat, y)\n",
        "    rec = macro_recall(yhat, y)\n",
        "    if prec + rec == 0:\n",
        "        f1 = 0.\n",
        "    else:\n",
        "        f1 = 2*(prec*rec)/(prec+rec)\n",
        "    return f1\n",
        "\n",
        "##########################################################################\n",
        "#MICRO METRICS: treat every prediction as an individual binary prediction\n",
        "##########################################################################\n",
        "\n",
        "def micro_accuracy(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / union_size(yhatmic, ymic, 0)\n",
        "\n",
        "def micro_precision(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / yhatmic.sum(axis=0)\n",
        "\n",
        "def micro_recall(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / ymic.sum(axis=0)\n",
        "\n",
        "def micro_f1(yhatmic, ymic):\n",
        "    prec = micro_precision(yhatmic, ymic)\n",
        "    rec = micro_recall(yhatmic, ymic)\n",
        "    if prec + rec == 0:\n",
        "        f1 = 0.\n",
        "    else:\n",
        "        f1 = 2*(prec*rec)/(prec+rec)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def all_macro(yhat, y):\n",
        "    return macro_accuracy(yhat, y), macro_precision(yhat, y), macro_recall(yhat, y), macro_f1(yhat, y)\n",
        "\n",
        "def all_micro(yhatmic, ymic):\n",
        "    return micro_accuracy(yhatmic, ymic), micro_precision(yhatmic, ymic), micro_recall(yhatmic, ymic), micro_f1(yhatmic, ymic)\n",
        "\n",
        "\n",
        "def all_metrics(yhat, y, yhat_raw=None, calc_auc=True, label_order=[]):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            yhat: binary predictions matrix \n",
        "            y: binary ground truth matrix\n",
        "            yhat_raw: prediction scores matrix (floats)\n",
        "        Outputs:\n",
        "            dict holding relevant metrics\n",
        "    \"\"\"\n",
        "    names = [\"acc\", \"prec\", \"rec\", \"f1\"]\n",
        "\n",
        "    metrics = {}\n",
        "    for ix,label in enumerate(label_order):\n",
        "        metrics[f\"{label2abbrev[label]}-f1\"] = f1_score(y[:,ix], yhat[:,ix])\n",
        "\n",
        "    #macro\n",
        "    #print(\"GETTING ALL MACRO\")\n",
        "    macro = all_macro(yhat, y)\n",
        "\n",
        "    #micro\n",
        "    #print(\"GETTING ALL MICRO\")\n",
        "    ymic = y.ravel()\n",
        "    yhatmic = yhat.ravel()\n",
        "    micro = all_micro(yhatmic, ymic)\n",
        "\n",
        "    metrics.update({names[i] + \"_macro\": macro[i] for i in range(len(macro))})\n",
        "    metrics.update({names[i] + \"_micro\": micro[i] for i in range(len(micro))})\n",
        "\n",
        "    #AUC\n",
        "    #print(\"AUC\")\n",
        "    if yhat_raw is not None and calc_auc:\n",
        "        roc_auc = auc_metrics(yhat_raw, y, ymic)\n",
        "        metrics.update(roc_auc)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "JfZ6qMlfd48u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dv_loader, device, tokenizer, return_thresholds=False, doc_position=False):\n",
        "    # apply model to validation set and compute metrics, including identifying best thresholds\n",
        "    yhat_raw, yhat, y, sentences, doc_ids, sent_ixs = gather_predictions(model, dv_loader, device)\n",
        "\n",
        "\n",
        "    # unbalanced metrics\n",
        "    metrics = all_metrics(yhat, y, yhat_raw=yhat_raw, calc_auc=True, label_order=LABEL_TYPES)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "mknFQXXeY0ks"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "\n",
        "max_epochs=5\n",
        "learning_rate=5e-5\n",
        "max_steps=-1\n",
        "gradient_accumulation_steps=4\n",
        "eval_steps = 100\n"
      ],
      "metadata": {
        "id": "kerxyrgGGTuY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "total_t0 = time.time()\n",
        "tr_loss = 0.0\n",
        "model.zero_grad()\n",
        "model.train()\n",
        "metrics_hist = defaultdict(list)\n",
        "best_epoch = 0\n",
        "best_step = 0\n",
        "step = 0\n",
        "losses = []\n",
        "for epoch in range(max_epochs):\n",
        "        step = 0\n",
        "        t0 = time.time()\n",
        "        for x in tqdm(train_dataloader):\n",
        "            if max_steps > -1 and step > max_steps:\n",
        "                break\n",
        "            # transfer to gpu\n",
        "            for k, v in x.items():\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    x[k] = v.to(device)\n",
        "            inputs = {'input_ids': x['input_ids'], 'attention_mask': x['attention_mask'], 'labels': x['labels']}\n",
        "            if 'token_type_ids' in x:\n",
        "              inputs['token_type_ids'] = x['token_type_ids']\n",
        "            #outputs = model(**inputs)\n",
        "            loss, pred = model(**inputs)\n",
        "\n",
        "            # update parameters\n",
        "            if gradient_accumulation_steps > 1:\n",
        "                loss = loss / gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % gradient_accumulation_steps == 0 or (\n",
        "                # last step in epoch but step is always smaller than gradient_accumulation_steps\n",
        "                len(train_dataloader) <= gradient_accumulation_steps\n",
        "                and (step + 1) == len(train_dataloader)\n",
        "            ):\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "                model.zero_grad()\n",
        "                losses.append(tr_loss)\n",
        "                tr_loss = 0.0\n",
        "\n",
        "\n",
        "            # tensor output\n",
        "            if (step + 1) % eval_steps == 0:\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), np.mean(losses[-10:]), elapsed))\n",
        "\n",
        "            step += 1\n",
        "\n",
        "#evaluation metrics\n",
        "metrics = evaluate(model, validation_dataloader, device, tokenizer=tokenizer1)\n",
        "for name, metric in metrics.items():\n",
        "  metrics_hist[name].append(metric)\n",
        "\n",
        "#test metrics\n",
        "metrics_hist_test = defaultdict(list)\n",
        "metrics_test = evaluate(model, test_dataloader, device, tokenizer=tokenizer1)\n",
        "for name, metric in metrics_test.items():\n",
        "  metrics_hist_test[name].append(metric)\n",
        "\n",
        "#save model\n",
        "out_dir = \"/content/drive/My Drive/Deep Learning Project\"\n",
        "sd = model.state_dict()\n",
        "torch.save(sd, out_dir + \"/model_final_BioClincial.pth\")\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGn65XaNTPNt",
        "outputId": "72d00588-2234-46d2-fc9d-73020a033f49"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1198 [00:00<?, ?it/s]<ipython-input-10-ec9cf2df673a>:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  labels = torch.Tensor(labels)\n",
            "  8%|▊         | 100/1198 [00:38<07:24,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    99  of  1,198. Loss: 0.18798042386770247.   Elapsed: 0:00:38.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 201/1198 [01:09<04:30,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   199  of  1,198. Loss: 0.1011527406051755.   Elapsed: 0:01:10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 301/1198 [01:44<03:51,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   299  of  1,198. Loss: 0.07052444708533585.   Elapsed: 0:01:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 400/1198 [02:15<04:18,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   399  of  1,198. Loss: 0.052933424315415326.   Elapsed: 0:02:16.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 500/1198 [02:46<02:11,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   499  of  1,198. Loss: 0.06251525122206658.   Elapsed: 0:02:46.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 600/1198 [03:20<03:18,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   599  of  1,198. Loss: 0.048913332051597536.   Elapsed: 0:03:21.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 701/1198 [03:55<01:49,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   699  of  1,198. Loss: 0.043844261299818756.   Elapsed: 0:03:55.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 801/1198 [04:27<01:55,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   799  of  1,198. Loss: 0.04724556610453874.   Elapsed: 0:04:27.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 901/1198 [04:58<01:48,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   899  of  1,198. Loss: 0.03728429033653811.   Elapsed: 0:04:58.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 1001/1198 [05:26<00:53,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   999  of  1,198. Loss: 0.041477080923505126.   Elapsed: 0:05:27.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1100/1198 [05:55<00:22,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,099  of  1,198. Loss: 0.040056271752109754.   Elapsed: 0:05:56.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1198/1198 [06:25<00:00,  3.11it/s]\n",
            "  8%|▊         | 100/1198 [00:35<07:24,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    99  of  1,198. Loss: 0.04472177331917919.   Elapsed: 0:00:36.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 201/1198 [01:06<04:29,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   199  of  1,198. Loss: 0.0328934132528957.   Elapsed: 0:01:07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 301/1198 [01:41<03:50,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   299  of  1,198. Loss: 0.029988906043581665.   Elapsed: 0:01:41.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 400/1198 [02:12<04:18,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   399  of  1,198. Loss: 0.02776574089657515.   Elapsed: 0:02:13.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 500/1198 [02:43<02:11,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   499  of  1,198. Loss: 0.03386275724624284.   Elapsed: 0:02:43.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 600/1198 [03:17<03:18,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   599  of  1,198. Loss: 0.03356903553358279.   Elapsed: 0:03:18.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 701/1198 [03:52<01:49,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   699  of  1,198. Loss: 0.022371929208748042.   Elapsed: 0:03:52.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 801/1198 [04:24<01:54,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   799  of  1,198. Loss: 0.02963237201620359.   Elapsed: 0:04:24.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 901/1198 [04:55<01:48,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   899  of  1,198. Loss: 0.027694344409974293.   Elapsed: 0:04:55.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 1001/1198 [05:23<00:53,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   999  of  1,198. Loss: 0.028871821489883587.   Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1100/1198 [05:52<00:22,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,099  of  1,198. Loss: 0.03018966636736877.   Elapsed: 0:05:53.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1198/1198 [06:22<00:00,  3.13it/s]\n",
            "  8%|▊         | 100/1198 [00:35<07:25,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    99  of  1,198. Loss: 0.034621725368197076.   Elapsed: 0:00:36.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 201/1198 [01:06<04:29,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   199  of  1,198. Loss: 0.024358938133809717.   Elapsed: 0:01:07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 301/1198 [01:41<03:51,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   299  of  1,198. Loss: 0.023234902147669344.   Elapsed: 0:01:41.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 400/1198 [02:12<04:18,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   399  of  1,198. Loss: 0.022095591493416576.   Elapsed: 0:02:13.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 500/1198 [02:43<02:11,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   499  of  1,198. Loss: 0.026451301234192214.   Elapsed: 0:02:43.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 600/1198 [03:17<03:18,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   599  of  1,198. Loss: 0.02563029950542841.   Elapsed: 0:03:18.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 701/1198 [03:51<01:49,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   699  of  1,198. Loss: 0.017591299075866117.   Elapsed: 0:03:52.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 801/1198 [04:24<01:55,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   799  of  1,198. Loss: 0.021640905033564195.   Elapsed: 0:04:24.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 901/1198 [04:54<01:48,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   899  of  1,198. Loss: 0.02182697125826962.   Elapsed: 0:04:55.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 1001/1198 [05:23<00:53,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   999  of  1,198. Loss: 0.024573367653647437.   Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1100/1198 [05:52<00:22,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,099  of  1,198. Loss: 0.025986023267614657.   Elapsed: 0:05:53.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1198/1198 [06:22<00:00,  3.13it/s]\n",
            "  8%|▊         | 100/1198 [00:35<07:24,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    99  of  1,198. Loss: 0.027512274641776458.   Elapsed: 0:00:36.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 201/1198 [01:06<04:29,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   199  of  1,198. Loss: 0.01927780747937504.   Elapsed: 0:01:07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 301/1198 [01:41<03:50,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   299  of  1,198. Loss: 0.019420328352134676.   Elapsed: 0:01:42.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 400/1198 [02:12<04:19,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   399  of  1,198. Loss: 0.01849491619359469.   Elapsed: 0:02:13.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 500/1198 [02:43<02:11,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   499  of  1,198. Loss: 0.022915302333422004.   Elapsed: 0:02:43.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 600/1198 [03:17<03:18,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   599  of  1,198. Loss: 0.02225398366281297.   Elapsed: 0:03:18.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 701/1198 [03:52<01:49,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   699  of  1,198. Loss: 0.014405238031758926.   Elapsed: 0:03:52.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 801/1198 [04:24<01:55,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   799  of  1,198. Loss: 0.01840077169035794.   Elapsed: 0:04:24.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 901/1198 [04:55<01:48,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   899  of  1,198. Loss: 0.01742238488077419.   Elapsed: 0:04:55.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 1001/1198 [05:23<00:53,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   999  of  1,198. Loss: 0.020125441362324636.   Elapsed: 0:05:24.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1100/1198 [05:52<00:22,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,099  of  1,198. Loss: 0.022010187638807112.   Elapsed: 0:05:53.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1198/1198 [06:22<00:00,  3.13it/s]\n",
            "  8%|▊         | 100/1198 [00:35<07:25,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    99  of  1,198. Loss: 0.022592314184294082.   Elapsed: 0:00:36.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 201/1198 [01:06<04:30,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   199  of  1,198. Loss: 0.01653091477637645.   Elapsed: 0:01:07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 301/1198 [01:41<03:51,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   299  of  1,198. Loss: 0.016439586268097627.   Elapsed: 0:01:41.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 400/1198 [02:12<04:20,  3.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   399  of  1,198. Loss: 0.01569100109336432.   Elapsed: 0:02:13.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 500/1198 [02:43<02:11,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   499  of  1,198. Loss: 0.019535391866520514.   Elapsed: 0:02:43.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 600/1198 [03:17<03:18,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   599  of  1,198. Loss: 0.019005494186421855.   Elapsed: 0:03:18.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 701/1198 [03:51<01:49,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   699  of  1,198. Loss: 0.013092208132729866.   Elapsed: 0:03:52.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 801/1198 [04:24<01:55,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   799  of  1,198. Loss: 0.016899962327443063.   Elapsed: 0:04:24.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 901/1198 [04:54<01:49,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   899  of  1,198. Loss: 0.014379937735793647.   Elapsed: 0:04:55.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 1001/1198 [05:23<00:54,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   999  of  1,198. Loss: 0.016178866534028204.   Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1100/1198 [05:52<00:22,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,099  of  1,198. Loss: 0.02017108709696913.   Elapsed: 0:05:53.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1198/1198 [06:22<00:00,  3.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics)\n",
        "print(metrics_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tViVfouZhryo",
        "outputId": "7792da83-f190-4ae0-aa31-4c38f53b2935"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Imaging-f1': 0.5479452054794521, 'Appointment-f1': 0.8454106280193237, 'Medication-f1': 0.6835820895522388, 'Procedure-f1': 0.5486725663716815, 'Lab-f1': 0.5347593582887701, 'Patient instructions-f1': 0.8407758231844836, 'Other-f1': 0.2, 'acc_macro': 0.45832366632079075, 'prec_macro': 0.5953648425113938, 'rec_macro': 0.6298090522890244, 'f1_macro': 0.6121027697694905, 'acc_micro': 0.6372653205809422, 'prec_micro': 0.765531914893617, 'rec_micro': 0.7918133802816901, 'f1_micro': 0.778450887061878, 'auc_macro': 0.9640015312768829, 'auc_micro': 0.9810778491530974}\n",
            "{'Imaging-f1': 0.6176470588235294, 'Appointment-f1': 0.8422597212032282, 'Medication-f1': 0.6613226452905812, 'Procedure-f1': 0.5238095238095237, 'Lab-f1': 0.672566371681416, 'Patient instructions-f1': 0.7829279486002754, 'Other-f1': 0.16513761467889906, 'acc_macro': 0.46615958800863017, 'prec_macro': 0.6453442423450563, 'rec_macro': 0.5979576220954591, 'f1_macro': 0.6207478965847043, 'acc_micro': 0.6125356125356125, 'prec_micro': 0.7843137254901961, 'rec_micro': 0.7366167023554604, 'f1_micro': 0.7597173144876325, 'auc_macro': 0.9596413379845237, 'auc_micro': 0.9705608834005989}\n"
          ]
        }
      ]
    }
  ]
}